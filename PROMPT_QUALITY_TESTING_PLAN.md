# Prompt Quality Testing Plan
## AI Music Generation - Enhanced Prompts v2.0

**Version**: 2.0
**Date**: 2025-11-20
**Status**: Ready for Execution
**Complements**: [TESTING_PLAN.md](TESTING_PLAN.md) (technical tests)

---

## ðŸŽ¯ Purpose

This plan focuses specifically on testing the **enhanced prompt templates** (v2.0) created in Phase 2, including:
- 20 few-shot examples (expanded from 4)
- Comprehensive Strudel syntax reference
- Music theory context (BPM, genres, chords)
- Enhanced refinement prompts

This is separate from (but complements) the technical testing in [TESTING_PLAN.md](TESTING_PLAN.md).

---

## ðŸ“Š Quick Reference

| Test Phase | Duration | Cost | Status |
|------------|----------|------|--------|
| Phase 1: Mock Validation | 30 min | Free | â¬œ Not Started |
| Phase 2: Quality Testing | 2-3 hours | ~$1-2 | â¬œ Not Started |
| Phase 3: Model Comparison | 3-4 hours | ~$5-10 | â¬œ Not Started |
| Phase 4: Iteration | Ongoing | Variable | â¬œ Not Started |

---

## Phase 1: Mock Validation âš¡ (Free & Fast)

### Objective
Confirm prompt templates render correctly without API costs.

### Setup
```bash
# Set mock mode
cat > .env << 'EOF'
USE_MOCK_AI=true
PORT=3001
CORS_ORIGIN=http://localhost:5173
NODE_ENV=development
EOF

# Start servers
cd packages/backend && npm run dev &
cd packages/frontend && npm run dev
```

### Tests

| # | Action | Expected Result | Status |
|---|--------|-----------------|--------|
| 1 | Submit "create a drum beat" | Returns mock Strudel code | â¬œ |
| 2 | Check response format | Contains markdown code block | â¬œ |
| 3 | Check template variables | `{{defaults}}`, `{{examples}}`, `{{user_prompt}}` replaced | â¬œ |
| 4 | Check few-shot examples | All 20 examples loaded | â¬œ |
| 5 | Submit refinement | Mock refinement response | â¬œ |
| 6 | Check console | No errors | â¬œ |

### Validation Checklist
- â¬œ Prompts load from files successfully
- â¬œ Examples render in correct format
- â¬œ No template syntax errors
- â¬œ Mock service returns formatted code
- â¬œ Refinement template works

**Exit Criteria**: All tests pass â†’ Move to Phase 2

---

## Phase 2: Quality Testing (Real AI - Claude 3.5 Sonnet)

### Setup
```bash
cat > .env << 'EOF'
USE_MOCK_AI=false
OPENROUTER_API_KEY=your_key_here
WHISPER_API_KEY=your_key_here
OPENROUTER_MODEL=anthropic/claude-3.5-sonnet
PORT=3001
CORS_ORIGIN=http://localhost:5173
EOF

# Restart backend
cd packages/backend && npm run dev
```

### Test Suite A: Syntax Validation (5 tests)

**Target**: 95%+ pass rate

| # | Prompt | Syntax Valid? | Runs in Strudel? | Notes |
|---|--------|---------------|------------------|-------|
| A1 | "Create a simple drum beat" | â¬œ | â¬œ | Basic s() usage |
| A2 | "Make a slow piano melody" | â¬œ | â¬œ | Note patterns |
| A3 | "Play a bassline" | â¬œ | â¬œ | Octave usage |
| A4 | "Create kick and snare pattern" | â¬œ | â¬œ | Classic pattern |
| A5 | "Generate hi-hats" | â¬œ | â¬œ | Repetition syntax |

**Pass Criteria**: Code executes without syntax errors

---

### Test Suite B: Genre Accuracy (10 tests)

**Target**: 4.0/5 average on all metrics

| # | Prompt | Genre (1-5) | Tempo (1-5) | Quality (1-5) | Notes |
|---|--------|-------------|-------------|---------------|-------|
| B1 | "Create a house track at 125 BPM" | â¬œ | â¬œ | â¬œ | Four-on-floor? |
| B2 | "Make a hip-hop beat with 808s at 90 BPM" | â¬œ | â¬œ | â¬œ | Syncopated? |
| B3 | "Generate a jazz chord progression" | â¬œ | â¬œ | â¬œ | Maj7/min7? |
| B4 | "Create techno with filtered bassline" | â¬œ | â¬œ | â¬œ | Uses .cutoff()? |
| B5 | "Make an ambient soundscape" | â¬œ | â¬œ | â¬œ | Reverb/delay? |
| B6 | "Create drum and bass at 170 BPM" | â¬œ | â¬œ | â¬œ | Fast breaks? |
| B7 | "Generate trap with hi-hat rolls" | â¬œ | â¬œ | â¬œ | Triplet hats? |
| B8 | "Make a reggae rhythm" | â¬œ | â¬œ | â¬œ | Offbeat chords? |
| B9 | "Create a funk groove" | â¬œ | â¬œ | â¬œ | Syncopated bass? |
| B10 | "Generate classical strings" | â¬œ | â¬œ | â¬œ | Harmonic chords? |

**Scoring Rubric**:
- **5**: Perfect - Exactly what was requested
- **4**: Good - Minor deviations
- **3**: Acceptable - Recognizable but off
- **2**: Poor - Wrong but functional
- **1**: Fail - Completely wrong

---

### Test Suite C: Advanced Features (5 tests)

**Target**: 80%+ feature usage, 4.0/5 creativity

| # | Prompt | Effects? | Modulation? | Transforms? | Creativity (1-5) | Notes |
|---|--------|----------|-------------|-------------|------------------|-------|
| C1 | "Create polyrhythmic percussion" | â¬œ | â¬œ | â¬œ (fast ratios) | â¬œ | 3/2, 5/4? |
| C2 | "Generate glitchy IDM" | â¬œ (distort) | â¬œ (rand) | â¬œ (sometimes) | â¬œ | Generative? |
| C3 | "Make dubstep wobble bass" | â¬œ (cutoff) | â¬œ (sine.range) | â¬œ | â¬œ | LFO? |
| C4 | "Create ambient with delay feedback" | â¬œ (delay) | â¬œ | â¬œ | â¬œ | .delayfeedback? |
| C5 | "Generate layered pattern (4+ elements)" | â¬œ | â¬œ | â¬œ | â¬œ | Uses stack()? |

---

### Test Suite D: Refinement Quality (7 tests)

**Target**: 4.5/5 on preservation and accuracy

| # | Base â†’ Refinement | Preservation (1-5) | Accuracy (1-5) | Notes |
|---|-------------------|-------------------|----------------|-------|
| D1 | "drum beat" â†’ "add hi-hats" | â¬œ | â¬œ | Original intact? |
| D2 | "house track" â†’ "make it faster" | â¬œ | â¬œ | Only setcps changed? |
| D3 | "piano melody" â†’ "add reverb" | â¬œ | â¬œ | Adds .room()? |
| D4 | "complex pattern" â†’ "simplify" | â¬œ | â¬œ | Reduces complexity? |
| D5 | "drum pattern" â†’ "remove snare, add rim" | â¬œ | â¬œ | Surgical swap? |
| D6 | "techno beat" â†’ "add bassline" | â¬œ | â¬œ | Layers with stack()? |
| D7 | "ambient" â†’ "make rhythmic" | â¬œ | â¬œ | Adds rhythm? |

**Preservation Scoring**:
- **5**: All original code preserved exactly
- **4**: Minor formatting changes only
- **3**: Some original elements changed unnecessarily
- **2**: Major rewrites of unchanged elements
- **1**: Complete rewrite (failure)

**Accuracy Scoring**:
- **5**: Perfect match to refinement request
- **4**: Good match, minor deviations
- **3**: Partial match
- **2**: Wrong change applied
- **1**: No change or opposite change

---

### Results Recording

For each test, create entry:

```markdown
## Test B3: Jazz Chord Progression

**Prompt**: "Generate a jazz chord progression"

**Generated Code**:
```javascript
setcps(0.8);
stack(
  n("<[cmaj7,e3,g3,b3] [fmaj7,f3,a3,c4] [g7,g3,b3,d4,f4]>")
    .s("piano").gain(0.7).slow(2),
  s("~ rim ~ rim").gain(0.5)
).swing()
```

**Execution**:
- âœ… Syntax valid
- âœ… Runs in Strudel
- âœ… Produces sound

**Scores**:
- Genre Match: 5/5 (Uses jazz chords, swing rhythm)
- Tempo: 4/5 (0.8 cps â‰ˆ 96 BPM, acceptable for jazz)
- Quality: 5/5 (Sounds great, proper voicings)

**Features**:
- âœ… Uses chord notation (maj7, min7)
- âœ… Uses .swing() transformation
- âœ… Appropriate tempo for genre
- âœ… Layered with subtle percussion

**Notes**: Excellent jazz generation. Uses our enhanced examples correctly.

**Audio**: [Link to recording if saved]
```

---

## Phase 3: Model Comparison

### Models to Test

| Model | ID | Cost/Req | Status |
|-------|----|----------|--------|
| **Claude 3.5 Sonnet** (baseline) | `anthropic/claude-3.5-sonnet` | $0.0105 | â¬œ |
| **GPT-4o** | `openai/gpt-4o` | $0.0135 | â¬œ |
| **GPT-4 Turbo** | `openai/gpt-4-turbo` | $0.027 | â¬œ |
| **Gemini 1.5 Pro** | `google/gemini-pro-1.5` | $0.00945 | â¬œ |

### Testing Procedure

For each model:

1. Update `.env`: `OPENROUTER_MODEL=model-id`
2. Restart backend
3. Run **Test Suite B** (10 genre tests)
4. Record all scores
5. Calculate weighted average
6. Note generation time and cost

### Comparison Spreadsheet

| Model | Avg Genre | Avg Tempo | Avg Quality | Weighted Score | Time (s) | Cost/Test |
|-------|-----------|-----------|-------------|----------------|----------|-----------|
| Claude Sonnet | â¬œ | â¬œ | â¬œ | â¬œ | â¬œ | $0.0105 |
| GPT-4o | â¬œ | â¬œ | â¬œ | â¬œ | â¬œ | $0.0135 |
| GPT-4 Turbo | â¬œ | â¬œ | â¬œ | â¬œ | â¬œ | $0.027 |
| Gemini Pro | â¬œ | â¬œ | â¬œ | â¬œ | â¬œ | $0.00945 |

**Weighted Score Formula**:
```
Score = (Genre*3 + Tempo*2 + Quality*5) / 10
Max = 5.0
```

### Model Selection

**Decision Criteria**:
1. Minimum threshold: Weighted Score â‰¥ 4.0
2. If multiple qualify: Choose best value (score per dollar)
3. Speed tiebreaker: Prefer faster if scores within 0.2

**Recommendation Template**:
```markdown
## Model Recommendation

**Winner**: [Model Name]

**Reasoning**:
- Score: X.X/5.0 (meets 4.0 threshold)
- Cost: $X.XX per request
- Speed: X.Xs average
- Value: Highest score-to-cost ratio

**Runners-up**:
1. [Model]: X.X/5.0 - [Reason not chosen]
2. [Model]: X.X/5.0 - [Reason not chosen]
```

---

## Phase 4: Iteration & Refinement

### Failure Analysis

For any test scoring < 3.5/5:

1. **Document Failure**:
   ```markdown
   - Test ID: B7
   - Prompt: "Generate trap with hi-hat rolls"
   - Score: 3.0/5 (Genre)
   - Issue: Missing triplet hi-hats, felt more like house
   ```

2. **Root Cause**:
   - â¬œ Missing genre example?
   - â¬œ Unclear instructions?
   - â¬œ Insufficient music theory?
   - â¬œ Model limitation?

3. **Proposed Fix**:
   - Add trap-specific example with triplet hats
   - Clarify genre characteristics in prompt
   - Add BPM guidance for trap (140-160)

4. **Re-test**:
   - Apply fix
   - Re-run same test
   - Validate improvement

5. **Document in** [PROMPT_OPTIMIZATION_LOG.md](PROMPT_OPTIMIZATION_LOG.md)

### Improvement Tracking

| Iteration | Syntax Rate | Genre Avg | Tempo Avg | Quality Avg | Refinement Avg |
|-----------|-------------|-----------|-----------|-------------|----------------|
| v1.0 (baseline) | 80% | 3.0/5 | 2.5/5 | 3.2/5 | 2.8/5 |
| v2.0 (current) | â¬œ | â¬œ | â¬œ | â¬œ | â¬œ |
| v2.1 (after fixes) | â¬œ | â¬œ | â¬œ | â¬œ | â¬œ |

**Target**: All metrics â‰¥ 4.0/5

---

## ðŸ“ Testing Checklist

### Before Starting
- â¬œ Backend/frontend installed
- â¬œ `.env` configured
- â¬œ OpenRouter API key funded
- â¬œ Spreadsheet/notes ready
- â¬œ Audio recording setup (optional)

### Phase 1 (Mock)
- â¬œ All 6 validation tests pass
- â¬œ No console errors
- â¬œ Templates render correctly

### Phase 2 (Real AI)
- â¬œ Run Test Suite A (5 tests)
- â¬œ Run Test Suite B (10 tests)
- â¬œ Run Test Suite C (5 tests)
- â¬œ Run Test Suite D (7 tests)
- â¬œ Calculate averages
- â¬œ Document findings

### Phase 3 (Models)
- â¬œ Test Claude 3.5 Sonnet
- â¬œ Test GPT-4o
- â¬œ Test GPT-4 Turbo
- â¬œ Test Gemini 1.5 Pro
- â¬œ Compare results
- â¬œ Select production model

### Phase 4 (Iterate)
- â¬œ Analyze failures (if any)
- â¬œ Implement fixes
- â¬œ Re-test
- â¬œ Document improvements

---

## ðŸš€ Quick Start

### Phase 1: Mock
```bash
echo "USE_MOCK_AI=true" > .env
npm run dev
# Test in browser: http://localhost:5173
```

### Phase 2: Real AI
```bash
cat > .env << 'EOF'
USE_MOCK_AI=false
OPENROUTER_API_KEY=your_key
OPENROUTER_MODEL=anthropic/claude-3.5-sonnet
EOF
cd packages/backend && npm run dev
```

### Phase 3: Switch Models
```bash
# Test GPT-4o
sed -i '' 's/OPENROUTER_MODEL=.*/OPENROUTER_MODEL=openai\/gpt-4o/' .env
# Restart backend
```

---

## ðŸ“Š Success Criteria

### Phase 1 Success
- â¬œ All templates load
- â¬œ All 20 examples render
- â¬œ No errors

### Phase 2 Success (v2.0 Prompts)
- â¬œ Syntax validity â‰¥ 95%
- â¬œ Genre accuracy â‰¥ 4.0/5
- â¬œ Tempo accuracy â‰¥ 4.0/5
- â¬œ Musical quality â‰¥ 4.0/5
- â¬œ Advanced features â‰¥ 80%
- â¬œ Refinement â‰¥ 4.5/5

### Phase 3 Success (Model Selection)
- â¬œ 3+ models tested
- â¬œ Clear winner identified
- â¬œ Recommendation documented

### Phase 4 Success (Iteration)
- â¬œ All failures analyzed
- â¬œ Fixes implemented
- â¬œ Improvement validated

---

## ðŸ“ˆ Expected vs. Actual Results

### Predictions (Phase 2 Expected)

Based on v2.0 enhancements:

| Metric | v1.0 Baseline | v2.0 Expected | Improvement |
|--------|---------------|---------------|-------------|
| Syntax Valid | 80% | 95% | +19% |
| Genre Accuracy | 3.0/5 | 4.2/5 | +40% |
| Tempo Accuracy | 2.5/5 | 4.5/5 | +80% |
| Quality | 3.2/5 | 4.3/5 | +34% |
| Refinement | 2.8/5 | 4.6/5 | +64% |

### Actual Results (To be filled after testing)

| Metric | Actual v2.0 | vs. Expected | vs. Baseline |
|--------|-------------|--------------|--------------|
| Syntax Valid | â¬œ | â¬œ | â¬œ |
| Genre Accuracy | â¬œ | â¬œ | â¬œ |
| Tempo Accuracy | â¬œ | â¬œ | â¬œ |
| Quality | â¬œ | â¬œ | â¬œ |
| Refinement | â¬œ | â¬œ | â¬œ |

---

## ðŸ”— Related Documents

- [TESTING_PLAN.md](TESTING_PLAN.md) - Technical testing (unit, integration, E2E)
- [MODEL_TESTING_GUIDE.md](MODEL_TESTING_GUIDE.md) - Detailed model comparison guide
- [PROMPT_OPTIMIZATION_LOG.md](PROMPT_OPTIMIZATION_LOG.md) - Results tracking
- [CLAUDE_PHASE2_COMPLETE.md](CLAUDE_PHASE2_COMPLETE.md) - What was improved in v2.0

---

## ðŸ’¾ Data Collection

Save results in:
- Spreadsheet: Google Sheets or local CSV
- Document: [PROMPT_OPTIMIZATION_LOG.md](PROMPT_OPTIMIZATION_LOG.md)
- Audio: Optional recordings of best examples

**CSV Template**:
```csv
Test_ID,Phase,Prompt,Model,Genre_Score,Tempo_Score,Quality_Score,Preservation_Score,Accuracy_Score,Notes
A1,2,"simple drum beat",claude-sonnet,5,5,4,N/A,N/A,"Perfect"
B1,2,"house 125 BPM",claude-sonnet,4,5,4,N/A,N/A,"Good layering"
```

---

**Last Updated**: 2025-11-20
**Version**: 2.0
**Status**: Ready for Execution
**Estimated Time**: 6-8 hours total
**Estimated Cost**: $5-15 (depending on models tested)

---

**Ready to begin testing!** Start with Phase 1 (mock validation) to verify everything works, then proceed to Phase 2 (real AI quality testing).
